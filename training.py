import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score
import joblib

# === Load Dataset ===
df = pd.read_csv("data/startup_sample_data.csv")
df = df.dropna()

# === Encode Categorical Columns ===
categorical_columns = ['industry', 'location', 'stage']
label_encoders = {}

for col in categorical_columns:
    if col in df.columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le
    else:
        print(f"‚ö†Ô∏è Column missing and skipped: {col}")

# === Separate Features and Target ===
target_column = "Success"
X = df.drop(columns=[target_column])
y = df[target_column]

# === Scale Numerical Features ===
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# === Train-Test Split ===
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# === Train Model ===
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# === Evaluate ===
y_pred = model.predict(X_test)
print("‚úÖ Accuracy:", accuracy_score(y_test, y_pred))
print("üìä Classification Report:\n", classification_report(y_test, y_pred))

# === Save Model Artifacts ===
os.makedirs("models", exist_ok=True)
joblib.dump(model, "models/model.pkl")
joblib.dump(scaler, "models/scaler.pkl")
joblib.dump(label_encoders, "models/label_encoders.pkl")
print("‚úÖ Model, scaler, and label encoders saved to 'models/'")
